{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"EXAMPLE: araBERT (initial Demo - TF) .ipynb","provenance":[{"file_id":"1KSy89fAkWt6EGfnFQElDjXrBror9lIZh","timestamp":1627671114406}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"Kx5r8J6WAwC_"},"source":["#Mount Drive"]},{"cell_type":"code","metadata":{"id":"TRoTl402AsZ8"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jenrhPyzE7ix"},"source":["#copy the BERT model to Colab\n","!mkdir arabert\n","!cp -r \"/content/drive/My Drive/arabert/\" ./"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"shok9wHKyI8L"},"source":["#Installing Java and pyarabic for Farasa\n","\n","To do Farasa segmenting you will need FarasaSegmenter.jar in the same directory as the preprocess.py file \n","\n","(you can get the Farasa segmenter from http://qatsdemo.cloudapp.net/farasa/register.html)"]},{"cell_type":"code","metadata":{"id":"nxf11ClKpMRn","colab":{"base_uri":"https://localhost:8080/","height":102},"executionInfo":{"status":"ok","timestamp":1580433425840,"user_tz":-120,"elapsed":9895,"user":{"displayName":"wissam antoun","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDSALPtIL3q2P36W-E2L313Aw1lXeeHSdDZNk-6-rg=s64","userId":"06574368210388800322"}},"outputId":"017a0847-418a-4f65-bc5d-d023ae7ce0d3"},"source":["#install java on colab (needed for Farasa)\n","import os       \n","def install_java():\n","  !apt-get install -y openjdk-8-jdk-headless -qq > /dev/null      #install openjdk\n","  os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"     #set environment variable\n","  !java -version       #check java version\n","install_java()\n","!pip install py4j\n","!pip install pyarabic "],"execution_count":null,"outputs":[{"output_type":"stream","text":["openjdk version \"11.0.5\" 2019-10-15\n","OpenJDK Runtime Environment (build 11.0.5+10-post-Ubuntu-0ubuntu1.118.04)\n","OpenJDK 64-Bit Server VM (build 11.0.5+10-post-Ubuntu-0ubuntu1.118.04, mixed mode, sharing)\n","Requirement already satisfied: py4j in /usr/local/lib/python3.6/dist-packages (0.10.9)\n","Requirement already satisfied: pyarabic in /usr/local/lib/python3.6/dist-packages (0.6.6)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"s7005rJmvsnB"},"source":["#This command is usefull when the java runtime hangs after a runtime restart (colab issue)\n","!pkill \"java\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ftnZYmKXrUIa"},"source":["#Clone the BERT repo that is compatible with our model\n","\n","The cloned repo is made compatible with the vocab token that that have \"\\[ \\]\" (for the link \\[رابط\\], for twitter handles \\[مستخدم\\], for emails \\[بريد\\] and for the \"+\" in the Farasa segmenter ex: \"الدراسات\"-->\"\\[ال+, دراس ,+ات\\]\"\n","\n","The preprocess file that we used is included in the araBERT repository,"]},{"cell_type":"code","metadata":{"id":"ufHaEOIoyOfe","colab":{"base_uri":"https://localhost:8080/","height":136},"executionInfo":{"status":"ok","timestamp":1580433432288,"user_tz":-120,"elapsed":2359,"user":{"displayName":"wissam antoun","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDSALPtIL3q2P36W-E2L313Aw1lXeeHSdDZNk-6-rg=s64","userId":"06574368210388800322"}},"outputId":"95ee3c00-3873-402b-db14-23366eea5c11"},"source":["!git clone https://github.com/WissamAntoun/bert #this implementation also has a compatible tokenizer"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Cloning into 'bert'...\n","remote: Enumerating objects: 32, done.\u001b[K\n","remote: Counting objects:   3% (1/32)\u001b[K\rremote: Counting objects:   6% (2/32)\u001b[K\rremote: Counting objects:   9% (3/32)\u001b[K\rremote: Counting objects:  12% (4/32)\u001b[K\rremote: Counting objects:  15% (5/32)\u001b[K\rremote: Counting objects:  18% (6/32)\u001b[K\rremote: Counting objects:  21% (7/32)\u001b[K\rremote: Counting objects:  25% (8/32)\u001b[K\rremote: Counting objects:  28% (9/32)\u001b[K\rremote: Counting objects:  31% (10/32)\u001b[K\rremote: Counting objects:  34% (11/32)\u001b[K\rremote: Counting objects:  37% (12/32)\u001b[K\rremote: Counting objects:  40% (13/32)\u001b[K\rremote: Counting objects:  43% (14/32)\u001b[K\rremote: Counting objects:  46% (15/32)\u001b[K\rremote: Counting objects:  50% (16/32)\u001b[K\rremote: Counting objects:  53% (17/32)\u001b[K\rremote: Counting objects:  56% (18/32)\u001b[K\rremote: Counting objects:  59% (19/32)\u001b[K\rremote: Counting objects:  62% (20/32)\u001b[K\rremote: Counting objects:  65% (21/32)\u001b[K\rremote: Counting objects:  68% (22/32)\u001b[K\rremote: Counting objects:  71% (23/32)\u001b[K\rremote: Counting objects:  75% (24/32)\u001b[K\rremote: Counting objects:  78% (25/32)\u001b[K\rremote: Counting objects:  81% (26/32)\u001b[K\rremote: Counting objects:  84% (27/32)\u001b[K\rremote: Counting objects:  87% (28/32)\u001b[K\rremote: Counting objects:  90% (29/32)\u001b[K\rremote: Counting objects:  93% (30/32)\u001b[K\rremote: Counting objects:  96% (31/32)\u001b[K\rremote: Counting objects: 100% (32/32)\u001b[K\rremote: Counting objects: 100% (32/32), done.\u001b[K\n","remote: Compressing objects: 100% (24/24), done.\u001b[K\n","remote: Total 391 (delta 18), reused 16 (delta 8), pack-reused 359\u001b[K\n","Receiving objects: 100% (391/391), 416.01 KiB | 10.95 MiB/s, done.\n","Resolving deltas: 100% (217/217), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LNRkHGtcGNkH","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1580433436483,"user_tz":-120,"elapsed":1926,"user":{"displayName":"wissam antoun","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDSALPtIL3q2P36W-E2L313Aw1lXeeHSdDZNk-6-rg=s64","userId":"06574368210388800322"}},"outputId":"674e57bb-1842-4118-ce78-24e4366118a3"},"source":["!mv ./FarasaSegmenterJar.jar ./bert"],"execution_count":null,"outputs":[{"output_type":"stream","text":["mv: cannot stat './FarasaSegmenterJar.jar': No such file or directory\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EFgvI-blyyY-"},"source":["import tensorflow as tf\n","from bert import tokenization\n","from bert.preprocess_arabert import preprocess\n","\n","#Mount your drive folder and configure the path to the araBERT folder\n","ARABERT_PATH = \"./arabert\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-kF8X1LgzDqY","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1580433506227,"user_tz":-120,"elapsed":654,"user":{"displayName":"wissam antoun","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDSALPtIL3q2P36W-E2L313Aw1lXeeHSdDZNk-6-rg=s64","userId":"06574368210388800322"}},"outputId":"3fb1fcea-aaed-416f-9141-449b72bbf6e5"},"source":["#test BERT tokenizer\n","bert_tokenizer = tokenization.FullTokenizer(ARABERT_PATH+\"/vocab.txt\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /content/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TkfeIGpO0NkP","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1580433507575,"user_tz":-120,"elapsed":822,"user":{"displayName":"wissam antoun","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDSALPtIL3q2P36W-E2L313Aw1lXeeHSdDZNk-6-rg=s64","userId":"06574368210388800322"}},"outputId":"1d327768-5f90-4c99-aaf7-4551d0ac98f9"},"source":["text = \" @arabert https://arabert.com الدراسات النظرية للتصميم الحديث\"\n","text_prep = preprocess(text)\n","print(text_prep)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[مستخدم] [رابط] ال+ دراس +ات ال+ نظري +ة ل+ ال+ تصميم ال+ حديث\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"riK3zuM60Kpq","colab":{"base_uri":"https://localhost:8080/","height":238},"executionInfo":{"status":"ok","timestamp":1580433511584,"user_tz":-120,"elapsed":661,"user":{"displayName":"wissam antoun","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDSALPtIL3q2P36W-E2L313Aw1lXeeHSdDZNk-6-rg=s64","userId":"06574368210388800322"}},"outputId":"4f6c94e1-e245-45fd-fe4e-292b17e0a759"},"source":["bert_tokenizer.tokenize(text_prep)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['[مستخدم]',\n"," '[رابط]',\n"," 'ال+',\n"," 'دراس',\n"," '+ات',\n"," 'ال+',\n"," 'نظري',\n"," '+ة',\n"," 'ل+',\n"," 'ال+',\n"," 'تصميم',\n"," 'ال+',\n"," 'حديث']"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"markdown","metadata":{"id":"Ka_J4XCy6xyY"},"source":["##Tensorflow Training"]},{"cell_type":"markdown","metadata":{"id":"TvsyptgP7Vz_"},"source":["**ENABLE GPU RUNTIME if your files are on drive or colab local drive!!!**\n","\n","Test Sentiment Analysis score on a dataset like the AJGT\n","\n","K. M. Alomari, H. M. ElSherif, and K. Shaalan, “Arabic tweets sentimental analysis using machine learning,” in Proceedings of the International Conference on Industrial, Engineering and Other Applications of Applied Intelligent Systems, pp. 602–610, Montreal, Canada, June 2017."]},{"cell_type":"code","metadata":{"id":"q8vC_Fnd6xNv","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1580435297987,"user_tz":-120,"elapsed":862,"user":{"displayName":"wissam antoun","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDSALPtIL3q2P36W-E2L313Aw1lXeeHSdDZNk-6-rg=s64","userId":"06574368210388800322"}},"outputId":"2418c848-4b98-4e9f-cbf3-5db66106a505"},"source":["import os\n","import sys\n","import json\n","import nltk\n","import random\n","import logging\n","import tensorflow as tf\n","import pandas as pd\n","\n","from glob import glob\n","from tensorflow.keras.utils import Progbar\n","from tqdm import tqdm\n","sys.path.append(\"bert\")\n","\n","import bert\n","from bert import modeling, optimization, tokenization\n","from bert.run_classifier import input_fn_builder, model_fn_builder\n","\n","from sklearn.model_selection import train_test_split\n","  \n","# configure logging\n","log = logging.getLogger('tensorflow')\n","log.setLevel(logging.INFO)\n","\n","# create formatter and add it to the handlers\n","formatter = logging.Formatter('%(asctime)s :  %(message)s')\n","sh = logging.StreamHandler()\n","sh.setLevel(logging.INFO)\n","sh.setFormatter(formatter)\n","log.handlers = [sh]\n","\n","if 'COLAB_TPU_ADDR' in os.environ:\n","  log.info(\"Using TPU runtime\")\n","  USE_TPU = True\n","  TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n","\n","  with tf.Session(TPU_ADDRESS) as session:\n","    log.info('TPU address is ' + TPU_ADDRESS)\n","    # Upload credentials to TPU.\n","    with open('/content/adc.json', 'r') as f:\n","      auth_info = json.load(f)\n","    tf.contrib.cloud.configure_gcs(session, credentials=auth_info)\n","    \n","else:\n","  log.warning('Not connected to TPU runtime')\n","  USE_TPU = False"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2020-01-31 01:48:17,157 :  Not connected to TPU runtime\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"ODrRSrYL78KM","colab":{"base_uri":"https://localhost:8080/","height":85},"executionInfo":{"status":"ok","timestamp":1580435302829,"user_tz":-120,"elapsed":692,"user":{"displayName":"wissam antoun","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDSALPtIL3q2P36W-E2L313Aw1lXeeHSdDZNk-6-rg=s64","userId":"06574368210388800322"}},"outputId":"f0515d95-6fed-4c0e-b854-6e63c431b44d"},"source":["# Input data pipeline config\n","TRAIN_BATCH_SIZE = 32 #@param {type:\"integer\"} #You can probably \n","                                              #increase when using TPUS\n","MAX_SEQ_LENGTH = 128 #@param {type:\"integer\"} #512 if running on TPU\n","\n","# Training procedure config\n","EVAL_BATCH_SIZE = 64 \n","LEARNING_RATE = 2e-5\n","NUM_TRAIN_EPOCHS = 6 #@param {type:\"integer\"}\n","WARMUP_PROPORTION = 0.1 #@param {type:\"number\"}\n","NUM_TPU_CORES = 8\n","PREDICT_BATCH_SIZE = 8\n","\n","CONFIG_FILE = os.path.join(ARABERT_PATH, \"bert_config.json\")\n","INIT_CHECKPOINT = os.path.join(ARABERT_PATH,\"arabert_model.ckpt\")\n","\n","OUTPUT_DIR_PER_MODEL = \"./finetuned_model\"\n","bert_config = modeling.BertConfig.from_json_file(CONFIG_FILE)\n","\n","log.info(\"Using checkpoint: {}\".format(INIT_CHECKPOINT))\n","\n","print(\"ARABERT_PATH: \"+ARABERT_PATH)\n","print(\"CONFIG_FILE: \"+CONFIG_FILE)\n","print(\"INIT_CHECKPOINT: \"+INIT_CHECKPOINT)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2020-01-31 01:48:22,175 :  Using checkpoint: ./arabert/arabert_model.ckpt\n"],"name":"stderr"},{"output_type":"stream","text":["ARABERT_PATH: ./arabert\n","CONFIG_FILE: ./arabert/bert_config.json\n","INIT_CHECKPOINT: ./arabert/arabert_model.ckpt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RERzE9788SkN"},"source":["df_AJGT = pd.read_excel('./bert/AJGT.xlsx',header=0)\n","\n","DATA_COLUMN = 'text'\n","LABEL_COLUMN = 'label'\n","\n","df_AJGT = df_AJGT[['Feed', 'Sentiment']]\n","df_AJGT.columns = [DATA_COLUMN, LABEL_COLUMN]\n","\n","df_AJGT['text'] = df_AJGT['text'].apply(lambda x: preprocess(x,True))\n","\n","train_AJGT, test_AJGT = train_test_split(df_AJGT, test_size=0.2,random_state=42)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MPIM4K2a80l3"},"source":["train_InputExamples = train_AJGT.apply(lambda x: bert.run_classifier.InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this example\n","                                                                    text_a = x[\"text\"], \n","                                                                    text_b = None, \n","                                                                    label = x[\"label\"]), axis = 1)\n","\n","test_InputExamples = test_AJGT.apply(lambda x: bert.run_classifier.InputExample(guid=None, \n","                                                                    text_a = x[\"text\"], \n","                                                                    text_b = None, \n","                                                                    label = x[\"label\"]), axis = 1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kReBtJo89p3K","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1580433560154,"user_tz":-120,"elapsed":981,"user":{"displayName":"wissam antoun","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDSALPtIL3q2P36W-E2L313Aw1lXeeHSdDZNk-6-rg=s64","userId":"06574368210388800322"}},"outputId":"aa1f2768-f66a-4c0c-a143-2ed1c32a7918"},"source":["labels = list(df_AJGT.label.unique())\n","print(labels)\n","\n","train_features = bert.run_classifier.convert_examples_to_features(train_InputExamples, labels, MAX_SEQ_LENGTH, bert_tokenizer)\n","test_features = bert.run_classifier.convert_examples_to_features(test_InputExamples, labels, MAX_SEQ_LENGTH, bert_tokenizer)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2020-01-31 01:19:19,286 :  From /content/bert/run_classifier.py:775: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n","\n","2020-01-31 01:19:19,288 :  Writing example 0 of 1440\n","2020-01-31 01:19:19,290 :  *** Example ***\n","2020-01-31 01:19:19,291 :  guid: None\n","2020-01-31 01:19:19,295 :  tokens: [CLS] سبحان الله ب+ حمد +ه عدد خلق +ه رضى نفس +ه زن +ه عرش +ه مداد كلم +ات +ه [SEP]\n","2020-01-31 01:19:19,296 :  input_ids: 29756 36006 12695 448 3945 129 5367 4095 129 4444 6746 129 630 129 5383 129 21336 6025 1012 129 29758 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","2020-01-31 01:19:19,299 :  input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","2020-01-31 01:19:19,300 :  segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","2020-01-31 01:19:19,301 :  label: Positive (id = 0)\n","2020-01-31 01:19:19,303 :  *** Example ***\n","2020-01-31 01:19:19,304 :  guid: None\n","2020-01-31 01:19:19,305 :  tokens: [CLS] سبحان الله مالك ال+ سمو +ات ال+ ارض [SEP]\n","2020-01-31 01:19:19,307 :  input_ids: 29756 36006 12695 20952 3000 4787 1012 3000 2889 29758 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","2020-01-31 01:19:19,307 :  input_mask: 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","2020-01-31 01:19:19,309 :  segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","2020-01-31 01:19:19,310 :  label: Positive (id = 0)\n","2020-01-31 01:19:19,313 :  *** Example ***\n","2020-01-31 01:19:19,314 :  guid: None\n","2020-01-31 01:19:19,318 :  tokens: [CLS] قص +ه جميل +ه جد +ا تعكس معنى ال+ ايمان ال+ تمسك ب+ ال ##ع ##قيد +ه ال+ صحيح ##ه حسن تعاليم +ها [SEP]\n","2020-01-31 01:19:19,319 :  input_ids: 29756 793 129 15724 129 503 124 14652 21906 3000 32291 3000 15008 448 445 996 28980 129 3000 18504 1004 3889 48933 1018 29758 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","2020-01-31 01:19:19,321 :  input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","2020-01-31 01:19:19,322 :  segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","2020-01-31 01:19:19,323 :  label: Positive (id = 0)\n","2020-01-31 01:19:19,325 :  *** Example ***\n","2020-01-31 01:19:19,326 :  guid: None\n","2020-01-31 01:19:19,327 :  tokens: [CLS] س+ نبق ##ى نذكر دول +ه ال+ شهيد و+ صف +ي ال+ تل الذي كان رييس +ا ل+ ال+ وزراء حبيب +ا ل+ ال+ فقراء [SEP]\n","2020-01-31 01:19:19,328 :  input_ids: 29756 635 6553 1006 22861 4274 129 3000 18347 897 683 130 3000 483 12691 5951 17335 124 816 3000 41130 15958 124 816 3000 37425 29758 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","2020-01-31 01:19:19,330 :  input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","2020-01-31 01:19:19,331 :  segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","2020-01-31 01:19:19,332 :  label: Negative (id = 1)\n","2020-01-31 01:19:19,334 :  *** Example ***\n","2020-01-31 01:19:19,335 :  guid: None\n","2020-01-31 01:19:19,336 :  tokens: [CLS] اول واحد ذكر ##نى ب+ صاحب اسم +ه قرد +ه [SEP]\n","2020-01-31 01:19:19,337 :  input_ids: 29756 3051 23631 4309 8214 448 18446 2917 129 5820 129 29758 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","2020-01-31 01:19:19,339 :  input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","2020-01-31 01:19:19,340 :  segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","2020-01-31 01:19:19,341 :  label: Negative (id = 1)\n"],"name":"stderr"},{"output_type":"stream","text":["['Positive', 'Negative']\n"],"name":"stdout"},{"output_type":"stream","text":["2020-01-31 01:19:19,680 :  Writing example 0 of 360\n","2020-01-31 01:19:19,681 :  *** Example ***\n","2020-01-31 01:19:19,683 :  guid: None\n","2020-01-31 01:19:19,684 :  tokens: [CLS] و+ الله حرام و+ الله موتو +ه ل+ شعب ال+ اردني من و ##ين بدن +ا نجيب ال+ كو من و ##ين يا الله ارحم ##و من في ال+ ارض يرحمك ##م من في ال+ سماء الله حرام [SEP]\n","2020-01-31 01:19:19,685 :  input_ids: 29756 897 12695 16006 897 12695 22398 129 816 4928 3000 31462 857 117 8268 3106 124 22786 3000 813 857 117 8268 900 12695 12271 1005 857 781 3000 2889 41768 1002 857 781 3000 17867 12695 16006 29758 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","2020-01-31 01:19:19,686 :  input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","2020-01-31 01:19:19,687 :  segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","2020-01-31 01:19:19,688 :  label: Negative (id = 1)\n","2020-01-31 01:19:19,689 :  *** Example ***\n","2020-01-31 01:19:19,690 :  guid: None\n","2020-01-31 01:19:19,692 :  tokens: [CLS] صباح ك+ سعيد [SEP]\n","2020-01-31 01:19:19,693 :  input_ids: 29756 18480 802 17782 29758 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","2020-01-31 01:19:19,694 :  input_mask: 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","2020-01-31 01:19:19,695 :  segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","2020-01-31 01:19:19,696 :  label: Positive (id = 0)\n","2020-01-31 01:19:19,697 :  *** Example ***\n","2020-01-31 01:19:19,698 :  guid: None\n","2020-01-31 01:19:19,699 :  tokens: [CLS] شخصي +ه تافه [SEP]\n","2020-01-31 01:19:19,700 :  input_ids: 29756 18162 129 13632 29758 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","2020-01-31 01:19:19,702 :  input_mask: 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","2020-01-31 01:19:19,703 :  segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","2020-01-31 01:19:19,704 :  label: Negative (id = 1)\n","2020-01-31 01:19:19,705 :  *** Example ***\n","2020-01-31 01:19:19,706 :  guid: None\n","2020-01-31 01:19:19,707 :  tokens: [CLS] ال+ حق مش على ل+ جن +ه ال+ تحكيم ال+ حق على ال+ اغب ##ي ##ه ال+ مشترك +ين [SEP]\n","2020-01-31 01:19:19,708 :  input_ids: 29756 3000 534 845 5467 816 514 129 3000 33337 3000 534 5467 3000 2964 1007 1004 3000 39431 1023 29758 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","2020-01-31 01:19:19,710 :  input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","2020-01-31 01:19:19,710 :  segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","2020-01-31 01:19:19,712 :  label: Negative (id = 1)\n","2020-01-31 01:19:19,713 :  *** Example ***\n","2020-01-31 01:19:19,714 :  guid: None\n","2020-01-31 01:19:19,715 :  tokens: [CLS] ل+ ما تكثر عليا ال+ التزام +ات يصير كل ال ##لي نفس +ي اس ##و +ي +ه استلق ##ي على ظهر ##ي و+ اس ##ولف ل+ ال+ سماء [SEP]\n","2020-01-31 01:19:19,717 :  input_ids: 29756 816 834 14878 19242 3000 47795 1012 24712 812 445 8175 6746 130 435 1005 130 129 31572 1007 5467 5317 1007 897 435 29487 816 3000 17867 29758 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","2020-01-31 01:19:19,718 :  input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","2020-01-31 01:19:19,719 :  segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","2020-01-31 01:19:19,720 :  label: Negative (id = 1)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"KfDMcI2l95Y9","colab":{"base_uri":"https://localhost:8080/","height":258},"executionInfo":{"status":"ok","timestamp":1580435306856,"user_tz":-120,"elapsed":710,"user":{"displayName":"wissam antoun","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDSALPtIL3q2P36W-E2L313Aw1lXeeHSdDZNk-6-rg=s64","userId":"06574368210388800322"}},"outputId":"cd2904a3-f589-45e2-ce34-a49afa291d50"},"source":["num_train_steps = int(len(train_features) / TRAIN_BATCH_SIZE * NUM_TRAIN_EPOCHS)\n","num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n","num_steps_per_epoch = int(len(train_features) / TRAIN_BATCH_SIZE)\n","\n","print(\"num train steps: {}\".format(num_train_steps))\n","print(\"num warmup steps: {}\".format(num_warmup_steps))\n","print(\"num_steps_per_epoch: {}\".format(num_steps_per_epoch))\n","\n","model_fn = model_fn_builder(\n","  bert_config=modeling.BertConfig.from_json_file(CONFIG_FILE),\n","  num_labels=2,\n","  init_checkpoint=INIT_CHECKPOINT,\n","  learning_rate=LEARNING_RATE,\n","  num_train_steps=num_train_steps,\n","  num_warmup_steps=num_warmup_steps,\n","  use_tpu=USE_TPU,\n","  use_one_hot_embeddings=USE_TPU\n",")\n","\n","tpu_cluster_resolver = None\n","if USE_TPU:\n","  tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(TPU_ADDRESS)\n","\n","run_config = tf.contrib.tpu.RunConfig(\n","    cluster=tpu_cluster_resolver,\n","    model_dir=OUTPUT_DIR_PER_MODEL,\n","    save_checkpoints_steps=num_steps_per_epoch,\n","    keep_checkpoint_max=0,\n","    tpu_config=tf.contrib.tpu.TPUConfig(\n","        iterations_per_loop=num_steps_per_epoch,\n","        num_shards=NUM_TPU_CORES,\n","        per_host_input_for_training=tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2))\n","\n","estimator = tf.contrib.tpu.TPUEstimator(\n","    use_tpu=USE_TPU,\n","    model_fn=model_fn,\n","    config=run_config,\n","    train_batch_size=TRAIN_BATCH_SIZE,\n","    eval_batch_size=EVAL_BATCH_SIZE,\n","    predict_batch_size=PREDICT_BATCH_SIZE)\n","  \n","train_input_fn = input_fn_builder(\n","    features=train_features,\n","    seq_length=MAX_SEQ_LENGTH,\n","    is_training=True,\n","    drop_remainder=USE_TPU)\n","\n","test_input_fn = input_fn_builder(\n","  features=test_features,\n","  seq_length=MAX_SEQ_LENGTH,\n","  is_training=False,\n","  drop_remainder=USE_TPU)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2020-01-31 01:48:26,198 :  Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fc3dfcd1d90>) includes params argument, but params are not passed to Estimator.\n","2020-01-31 01:48:26,201 :  Using config: {'_model_dir': './finetuned_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 45, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n","graph_options {\n","  rewrite_options {\n","    meta_optimizer_iterations: ONE\n","  }\n","}\n",", '_keep_checkpoint_max': 0, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc3dfc52be0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=45, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': None}\n","2020-01-31 01:48:26,202 :  _TPUContext: eval_on_tpu True\n","2020-01-31 01:48:26,204 :  eval_on_tpu ignored because use_tpu is False.\n"],"name":"stderr"},{"output_type":"stream","text":["num train steps: 270\n","num warmup steps: 27\n","num_steps_per_epoch: 45\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"EaIt17wo-8dU"},"source":["##Train the model"]},{"cell_type":"code","metadata":{"id":"gxZTFBMgOhbU"},"source":["os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yFAHCPW--tdY","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1580435786609,"user_tz":-120,"elapsed":345233,"user":{"displayName":"wissam antoun","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDSALPtIL3q2P36W-E2L313Aw1lXeeHSdDZNk-6-rg=s64","userId":"06574368210388800322"}},"outputId":"244ce6bb-8185-4d31-e964-f6363e40d533"},"source":["print(f'Beginning Training!')\n","estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Beginning Training!\n"],"name":"stdout"},{"output_type":"stream","text":["2020-01-31 01:50:41,886 :  Calling model_fn.\n","2020-01-31 01:50:41,887 :  Running train on CPU\n","2020-01-31 01:50:41,888 :  *** Features ***\n","2020-01-31 01:50:41,889 :    name = input_ids, shape = (32, 128)\n","2020-01-31 01:50:41,890 :    name = input_mask, shape = (32, 128)\n","2020-01-31 01:50:41,892 :    name = label_ids, shape = (32,)\n","2020-01-31 01:50:41,893 :    name = segment_ids, shape = (32, 128)\n","2020-01-31 01:50:44,568 :  **** Trainable Variables ****\n","2020-01-31 01:50:44,569 :    name = bert/embeddings/word_embeddings:0, shape = (64000, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,569 :    name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,573 :    name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,578 :    name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,582 :    name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,583 :    name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,584 :    name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,585 :    name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,587 :    name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,589 :    name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,592 :    name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,594 :    name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,595 :    name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,597 :    name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,599 :    name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,601 :    name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,603 :    name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,606 :    name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,607 :    name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,610 :    name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,612 :    name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,614 :    name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,616 :    name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,619 :    name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,619 :    name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,621 :    name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,622 :    name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,628 :    name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,630 :    name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,633 :    name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,635 :    name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,637 :    name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,639 :    name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,641 :    name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,643 :    name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,646 :    name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,648 :    name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,649 :    name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,650 :    name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,652 :    name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,653 :    name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,655 :    name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,656 :    name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,657 :    name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,658 :    name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,659 :    name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,660 :    name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,662 :    name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,663 :    name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,665 :    name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,666 :    name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,667 :    name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,668 :    name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,670 :    name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,671 :    name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,672 :    name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,673 :    name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,675 :    name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,676 :    name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,677 :    name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,678 :    name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,680 :    name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,681 :    name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,682 :    name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,683 :    name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,685 :    name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,686 :    name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,687 :    name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,688 :    name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,690 :    name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,691 :    name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,692 :    name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,693 :    name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,695 :    name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,695 :    name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,697 :    name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,698 :    name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,700 :    name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,701 :    name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,702 :    name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,704 :    name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,705 :    name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,706 :    name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,707 :    name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,709 :    name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,710 :    name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,711 :    name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,712 :    name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,713 :    name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,715 :    name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,716 :    name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,717 :    name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,718 :    name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,719 :    name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,721 :    name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,722 :    name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,723 :    name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,725 :    name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,726 :    name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,727 :    name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,728 :    name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,729 :    name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,731 :    name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,732 :    name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,733 :    name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,734 :    name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,735 :    name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,737 :    name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,738 :    name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,739 :    name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,741 :    name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,742 :    name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,743 :    name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,744 :    name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,746 :    name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,747 :    name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,748 :    name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,749 :    name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,751 :    name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,752 :    name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,754 :    name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,755 :    name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,757 :    name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,758 :    name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,759 :    name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,761 :    name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,762 :    name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,763 :    name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,765 :    name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,766 :    name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,767 :    name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,768 :    name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,770 :    name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,771 :    name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,772 :    name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,773 :    name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,774 :    name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,776 :    name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,777 :    name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,779 :    name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,780 :    name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,781 :    name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,783 :    name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,784 :    name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,786 :    name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,787 :    name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,788 :    name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,790 :    name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,791 :    name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,793 :    name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,794 :    name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,796 :    name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,797 :    name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,798 :    name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,800 :    name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,801 :    name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,802 :    name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,803 :    name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,805 :    name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,807 :    name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,808 :    name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,809 :    name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,810 :    name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,811 :    name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,812 :    name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,813 :    name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,815 :    name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,817 :    name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,818 :    name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,819 :    name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,820 :    name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,821 :    name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,823 :    name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,824 :    name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,825 :    name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,827 :    name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,828 :    name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,829 :    name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,830 :    name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,831 :    name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,832 :    name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,834 :    name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,836 :    name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,837 :    name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,838 :    name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,839 :    name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,840 :    name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,841 :    name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,841 :    name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,844 :    name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,845 :    name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,847 :    name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,848 :    name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,849 :    name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,850 :    name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,851 :    name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,853 :    name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,854 :    name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,855 :    name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:50:44,856 :    name = output_weights:0, shape = (2, 768)\n","2020-01-31 01:50:44,857 :    name = output_bias:0, shape = (2,)\n","2020-01-31 01:50:50,550 :  Done calling model_fn.\n","2020-01-31 01:50:50,552 :  Create CheckpointSaverHook.\n","2020-01-31 01:50:51,709 :  Graph was finalized.\n","2020-01-31 01:50:51,720 :  Restoring parameters from ./finetuned_model/model.ckpt-0\n","2020-01-31 01:50:54,094 :  Running local_init_op.\n","2020-01-31 01:50:54,323 :  Done running local_init_op.\n","2020-01-31 01:51:00,173 :  Saving checkpoints for 0 into ./finetuned_model/model.ckpt.\n","2020-01-31 01:51:22,191 :  global_step/sec: 0.479935\n","2020-01-31 01:51:22,192 :  examples/sec: 15.3579\n","2020-01-31 01:51:24,769 :  global_step/sec: 1.16398\n","2020-01-31 01:51:24,770 :  examples/sec: 37.2472\n","2020-01-31 01:51:27,362 :  global_step/sec: 1.15687\n","2020-01-31 01:51:27,366 :  examples/sec: 37.0197\n","2020-01-31 01:51:29,968 :  global_step/sec: 1.15096\n","2020-01-31 01:51:29,969 :  examples/sec: 36.8307\n","2020-01-31 01:51:32,579 :  global_step/sec: 1.14909\n","2020-01-31 01:51:32,580 :  examples/sec: 36.771\n","2020-01-31 01:51:35,193 :  global_step/sec: 1.14748\n","2020-01-31 01:51:35,195 :  examples/sec: 36.7192\n","2020-01-31 01:51:37,806 :  global_step/sec: 1.14826\n","2020-01-31 01:51:37,807 :  examples/sec: 36.7443\n","2020-01-31 01:51:40,434 :  global_step/sec: 1.14172\n","2020-01-31 01:51:40,435 :  examples/sec: 36.5352\n","2020-01-31 01:51:43,070 :  global_step/sec: 1.13782\n","2020-01-31 01:51:43,071 :  examples/sec: 36.4102\n","2020-01-31 01:51:45,713 :  global_step/sec: 1.13513\n","2020-01-31 01:51:45,714 :  examples/sec: 36.3243\n","2020-01-31 01:51:48,369 :  global_step/sec: 1.12976\n","2020-01-31 01:51:48,370 :  examples/sec: 36.1522\n","2020-01-31 01:51:51,034 :  global_step/sec: 1.12572\n","2020-01-31 01:51:51,035 :  examples/sec: 36.0229\n","2020-01-31 01:51:53,701 :  global_step/sec: 1.12472\n","2020-01-31 01:51:53,702 :  examples/sec: 35.991\n","2020-01-31 01:51:56,392 :  global_step/sec: 1.11477\n","2020-01-31 01:51:56,393 :  examples/sec: 35.6727\n","2020-01-31 01:51:58,178 :  Saving checkpoints for 45 into ./finetuned_model/model.ckpt.\n","2020-01-31 01:52:06,070 :  ./finetuned_model/model.ckpt-45 is not in all_model_checkpoint_paths. Manually adding it.\n","2020-01-31 01:52:09,304 :  global_step/sec: 0.232345\n","2020-01-31 01:52:09,307 :  examples/sec: 7.43503\n","2020-01-31 01:52:12,012 :  global_step/sec: 1.1078\n","2020-01-31 01:52:12,013 :  examples/sec: 35.4496\n","2020-01-31 01:52:14,694 :  global_step/sec: 1.11836\n","2020-01-31 01:52:14,696 :  examples/sec: 35.7876\n","2020-01-31 01:52:17,389 :  global_step/sec: 1.1133\n","2020-01-31 01:52:17,390 :  examples/sec: 35.6255\n","2020-01-31 01:52:20,108 :  global_step/sec: 1.10352\n","2020-01-31 01:52:20,111 :  examples/sec: 35.3125\n","2020-01-31 01:52:22,830 :  global_step/sec: 1.10221\n","2020-01-31 01:52:22,832 :  examples/sec: 35.2706\n","2020-01-31 01:52:25,568 :  global_step/sec: 1.09566\n","2020-01-31 01:52:25,569 :  examples/sec: 35.0612\n","2020-01-31 01:52:28,313 :  global_step/sec: 1.09261\n","2020-01-31 01:52:28,316 :  examples/sec: 34.9636\n","2020-01-31 01:52:31,057 :  global_step/sec: 1.09335\n","2020-01-31 01:52:31,058 :  examples/sec: 34.9873\n","2020-01-31 01:52:33,814 :  global_step/sec: 1.08836\n","2020-01-31 01:52:33,815 :  examples/sec: 34.8276\n","2020-01-31 01:52:36,563 :  global_step/sec: 1.09119\n","2020-01-31 01:52:36,564 :  examples/sec: 34.9182\n","2020-01-31 01:52:39,323 :  global_step/sec: 1.08699\n","2020-01-31 01:52:39,326 :  examples/sec: 34.7836\n","2020-01-31 01:52:42,069 :  global_step/sec: 1.09247\n","2020-01-31 01:52:42,070 :  examples/sec: 34.9591\n","2020-01-31 01:52:44,795 :  global_step/sec: 1.1006\n","2020-01-31 01:52:44,796 :  examples/sec: 35.2193\n","2020-01-31 01:52:47,518 :  global_step/sec: 1.10177\n","2020-01-31 01:52:47,519 :  examples/sec: 35.2566\n","2020-01-31 01:52:49,330 :  Saving checkpoints for 90 into ./finetuned_model/model.ckpt.\n","2020-01-31 01:52:57,851 :  ./finetuned_model/model.ckpt-90 is not in all_model_checkpoint_paths. Manually adding it.\n","2020-01-31 01:53:01,313 :  global_step/sec: 0.217457\n","2020-01-31 01:53:01,316 :  examples/sec: 6.95862\n","2020-01-31 01:53:03,985 :  global_step/sec: 1.1231\n","2020-01-31 01:53:03,986 :  examples/sec: 35.9391\n","2020-01-31 01:53:06,632 :  global_step/sec: 1.13316\n","2020-01-31 01:53:06,633 :  examples/sec: 36.2611\n","2020-01-31 01:53:09,295 :  global_step/sec: 1.12674\n","2020-01-31 01:53:09,296 :  examples/sec: 36.0555\n","2020-01-31 01:53:11,967 :  global_step/sec: 1.12273\n","2020-01-31 01:53:11,968 :  examples/sec: 35.9274\n","2020-01-31 01:53:14,647 :  global_step/sec: 1.11933\n","2020-01-31 01:53:14,648 :  examples/sec: 35.8185\n","2020-01-31 01:53:17,339 :  global_step/sec: 1.11438\n","2020-01-31 01:53:17,340 :  examples/sec: 35.6603\n","2020-01-31 01:53:20,039 :  global_step/sec: 1.11105\n","2020-01-31 01:53:20,040 :  examples/sec: 35.5535\n","2020-01-31 01:53:22,751 :  global_step/sec: 1.10609\n","2020-01-31 01:53:22,752 :  examples/sec: 35.3949\n","2020-01-31 01:53:25,474 :  global_step/sec: 1.10188\n","2020-01-31 01:53:25,475 :  examples/sec: 35.2602\n","2020-01-31 01:53:28,198 :  global_step/sec: 1.10149\n","2020-01-31 01:53:28,199 :  examples/sec: 35.2478\n","2020-01-31 01:53:30,924 :  global_step/sec: 1.10022\n","2020-01-31 01:53:30,925 :  examples/sec: 35.207\n","2020-01-31 01:53:33,662 :  global_step/sec: 1.09589\n","2020-01-31 01:53:33,663 :  examples/sec: 35.0683\n","2020-01-31 01:53:36,400 :  global_step/sec: 1.09553\n","2020-01-31 01:53:36,401 :  examples/sec: 35.0569\n","2020-01-31 01:53:39,121 :  global_step/sec: 1.10267\n","2020-01-31 01:53:39,122 :  examples/sec: 35.2855\n","2020-01-31 01:53:40,937 :  Saving checkpoints for 135 into ./finetuned_model/model.ckpt.\n","2020-01-31 01:53:49,604 :  ./finetuned_model/model.ckpt-135 is not in all_model_checkpoint_paths. Manually adding it.\n","2020-01-31 01:53:52,359 :  global_step/sec: 0.226615\n","2020-01-31 01:53:52,360 :  examples/sec: 7.25167\n","2020-01-31 01:53:55,046 :  global_step/sec: 1.11642\n","2020-01-31 01:53:55,047 :  examples/sec: 35.7255\n","2020-01-31 01:53:57,707 :  global_step/sec: 1.12772\n","2020-01-31 01:53:57,710 :  examples/sec: 36.0872\n","2020-01-31 01:54:00,386 :  global_step/sec: 1.11943\n","2020-01-31 01:54:00,388 :  examples/sec: 35.8218\n","2020-01-31 01:54:03,078 :  global_step/sec: 1.11453\n","2020-01-31 01:54:03,079 :  examples/sec: 35.6648\n","2020-01-31 01:54:05,776 :  global_step/sec: 1.11195\n","2020-01-31 01:54:05,777 :  examples/sec: 35.5825\n","2020-01-31 01:54:08,484 :  global_step/sec: 1.10784\n","2020-01-31 01:54:08,485 :  examples/sec: 35.4508\n","2020-01-31 01:54:11,204 :  global_step/sec: 1.10284\n","2020-01-31 01:54:11,205 :  examples/sec: 35.2907\n","2020-01-31 01:54:13,940 :  global_step/sec: 1.09661\n","2020-01-31 01:54:13,941 :  examples/sec: 35.0914\n","2020-01-31 01:54:16,675 :  global_step/sec: 1.09699\n","2020-01-31 01:54:16,676 :  examples/sec: 35.1037\n","2020-01-31 01:54:19,411 :  global_step/sec: 1.09656\n","2020-01-31 01:54:19,412 :  examples/sec: 35.0901\n","2020-01-31 01:54:22,152 :  global_step/sec: 1.09426\n","2020-01-31 01:54:22,153 :  examples/sec: 35.0163\n","2020-01-31 01:54:24,889 :  global_step/sec: 1.09625\n","2020-01-31 01:54:24,890 :  examples/sec: 35.0799\n","2020-01-31 01:54:27,615 :  global_step/sec: 1.1004\n","2020-01-31 01:54:27,616 :  examples/sec: 35.2128\n","2020-01-31 01:54:30,340 :  global_step/sec: 1.10108\n","2020-01-31 01:54:30,341 :  examples/sec: 35.2345\n","2020-01-31 01:54:32,155 :  Saving checkpoints for 180 into ./finetuned_model/model.ckpt.\n","2020-01-31 01:54:42,208 :  ./finetuned_model/model.ckpt-180 is not in all_model_checkpoint_paths. Manually adding it.\n","2020-01-31 01:54:44,031 :  global_step/sec: 0.219112\n","2020-01-31 01:54:44,037 :  examples/sec: 7.01158\n","2020-01-31 01:54:46,708 :  global_step/sec: 1.12089\n","2020-01-31 01:54:46,709 :  examples/sec: 35.8686\n","2020-01-31 01:54:49,366 :  global_step/sec: 1.12863\n","2020-01-31 01:54:49,367 :  examples/sec: 36.1161\n","2020-01-31 01:54:52,040 :  global_step/sec: 1.12183\n","2020-01-31 01:54:52,041 :  examples/sec: 35.8987\n","2020-01-31 01:54:54,730 :  global_step/sec: 1.1152\n","2020-01-31 01:54:54,731 :  examples/sec: 35.6863\n","2020-01-31 01:54:57,421 :  global_step/sec: 1.11495\n","2020-01-31 01:54:57,424 :  examples/sec: 35.6783\n","2020-01-31 01:55:00,132 :  global_step/sec: 1.10642\n","2020-01-31 01:55:00,135 :  examples/sec: 35.4055\n","2020-01-31 01:55:02,851 :  global_step/sec: 1.10329\n","2020-01-31 01:55:02,853 :  examples/sec: 35.3054\n","2020-01-31 01:55:05,570 :  global_step/sec: 1.10342\n","2020-01-31 01:55:05,571 :  examples/sec: 35.3095\n","2020-01-31 01:55:08,303 :  global_step/sec: 1.09803\n","2020-01-31 01:55:08,304 :  examples/sec: 35.1369\n","2020-01-31 01:55:11,039 :  global_step/sec: 1.09626\n","2020-01-31 01:55:11,040 :  examples/sec: 35.0802\n","2020-01-31 01:55:13,782 :  global_step/sec: 1.09365\n","2020-01-31 01:55:13,785 :  examples/sec: 34.9967\n","2020-01-31 01:55:16,514 :  global_step/sec: 1.09799\n","2020-01-31 01:55:16,515 :  examples/sec: 35.1358\n","2020-01-31 01:55:19,233 :  global_step/sec: 1.10342\n","2020-01-31 01:55:19,237 :  examples/sec: 35.3093\n","2020-01-31 01:55:21,956 :  global_step/sec: 1.10191\n","2020-01-31 01:55:21,957 :  examples/sec: 35.2612\n","2020-01-31 01:55:23,766 :  Saving checkpoints for 225 into ./finetuned_model/model.ckpt.\n","2020-01-31 01:55:32,582 :  ./finetuned_model/model.ckpt-225 is not in all_model_checkpoint_paths. Manually adding it.\n","2020-01-31 01:55:35,564 :  global_step/sec: 0.220459\n","2020-01-31 01:55:35,565 :  examples/sec: 7.05469\n","2020-01-31 01:55:38,236 :  global_step/sec: 1.12262\n","2020-01-31 01:55:38,240 :  examples/sec: 35.924\n","2020-01-31 01:55:40,884 :  global_step/sec: 1.13299\n","2020-01-31 01:55:40,885 :  examples/sec: 36.2557\n","2020-01-31 01:55:43,558 :  global_step/sec: 1.12195\n","2020-01-31 01:55:43,559 :  examples/sec: 35.9024\n","2020-01-31 01:55:46,235 :  global_step/sec: 1.12069\n","2020-01-31 01:55:46,236 :  examples/sec: 35.862\n","2020-01-31 01:55:48,916 :  global_step/sec: 1.11881\n","2020-01-31 01:55:48,917 :  examples/sec: 35.8018\n","2020-01-31 01:55:51,615 :  global_step/sec: 1.11152\n","2020-01-31 01:55:51,616 :  examples/sec: 35.5687\n","2020-01-31 01:55:54,324 :  global_step/sec: 1.10748\n","2020-01-31 01:55:54,325 :  examples/sec: 35.4395\n","2020-01-31 01:55:57,054 :  global_step/sec: 1.09907\n","2020-01-31 01:55:57,055 :  examples/sec: 35.1702\n","2020-01-31 01:55:59,794 :  global_step/sec: 1.09492\n","2020-01-31 01:55:59,795 :  examples/sec: 35.0376\n","2020-01-31 01:56:02,535 :  global_step/sec: 1.09435\n","2020-01-31 01:56:02,536 :  examples/sec: 35.019\n","2020-01-31 01:56:05,273 :  global_step/sec: 1.09551\n","2020-01-31 01:56:05,274 :  examples/sec: 35.0562\n","2020-01-31 01:56:08,027 :  global_step/sec: 1.0894\n","2020-01-31 01:56:08,028 :  examples/sec: 34.8608\n","2020-01-31 01:56:10,774 :  global_step/sec: 1.09212\n","2020-01-31 01:56:10,775 :  examples/sec: 34.9479\n","2020-01-31 01:56:13,517 :  global_step/sec: 1.09384\n","2020-01-31 01:56:13,518 :  examples/sec: 35.0027\n","2020-01-31 01:56:15,352 :  Saving checkpoints for 270 into ./finetuned_model/model.ckpt.\n","2020-01-31 01:56:24,830 :  ./finetuned_model/model.ckpt-270 is not in all_model_checkpoint_paths. Manually adding it.\n","2020-01-31 01:56:26,042 :  Loss for final step: 0.00047850437.\n","2020-01-31 01:56:26,044 :  training_loop marked as finished\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow_estimator.python.estimator.tpu.tpu_estimator.TPUEstimator at 0x7fc3dfc37eb8>"]},"metadata":{"tags":[]},"execution_count":63}]},{"cell_type":"markdown","metadata":{"id":"_GqBb9JI--pg"},"source":["##Evaluate the model on all saved checkpoint files"]},{"cell_type":"code","metadata":{"id":"YE2vyARj-2jH","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1580435961429,"user_tz":-120,"elapsed":171608,"user":{"displayName":"wissam antoun","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDSALPtIL3q2P36W-E2L313Aw1lXeeHSdDZNk-6-rg=s64","userId":"06574368210388800322"}},"outputId":"40dc024d-ea9a-4c5f-c944-e8a998b1e785"},"source":["print(f'Beginning Evaluation!')\n","eval_model_files = tf.gfile.Glob(os.path.join(OUTPUT_DIR_PER_MODEL,'*index'))\n","\n","for eval_checkpoint in tqdm(sorted(eval_model_files,key=lambda x: int(x[0:-6].split('-')[-1]))):\n","  result = estimator.evaluate(input_fn=test_input_fn, steps=int(len(test_features)/EVAL_BATCH_SIZE),checkpoint_path=eval_checkpoint[0:-6])\n","  tf.logging.info(\"***** Eval results *****\")\n","  for key in sorted(result.keys()):\n","    tf.logging.info(\"  %s = %s\", key, str(result[key]))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\r  0%|          | 0/7 [00:00<?, ?it/s]2020-01-31 01:56:30,066 :  Calling model_fn.\n","2020-01-31 01:56:30,066 :  Running eval on CPU\n","2020-01-31 01:56:30,067 :  *** Features ***\n","2020-01-31 01:56:30,069 :    name = input_ids, shape = (64, 128)\n","2020-01-31 01:56:30,071 :    name = input_mask, shape = (64, 128)\n","2020-01-31 01:56:30,073 :    name = label_ids, shape = (64,)\n","2020-01-31 01:56:30,074 :    name = segment_ids, shape = (64, 128)\n"],"name":"stderr"},{"output_type":"stream","text":["Beginning Evaluation!\n"],"name":"stdout"},{"output_type":"stream","text":["2020-01-31 01:56:32,058 :  **** Trainable Variables ****\n","2020-01-31 01:56:32,060 :    name = bert/embeddings/word_embeddings:0, shape = (64000, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,060 :    name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,068 :    name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,071 :    name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,073 :    name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,075 :    name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,077 :    name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,079 :    name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,081 :    name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,088 :    name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,090 :    name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,093 :    name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,096 :    name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,097 :    name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,099 :    name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,101 :    name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,104 :    name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,106 :    name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,106 :    name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,108 :    name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,110 :    name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,112 :    name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,113 :    name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,114 :    name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,117 :    name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,118 :    name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,120 :    name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,122 :    name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,123 :    name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,125 :    name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,126 :    name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,128 :    name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,129 :    name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,131 :    name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,132 :    name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,133 :    name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,134 :    name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,136 :    name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,138 :    name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,140 :    name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,141 :    name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,143 :    name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,144 :    name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,145 :    name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,147 :    name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,148 :    name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,150 :    name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,151 :    name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,153 :    name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,154 :    name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,155 :    name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,157 :    name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,158 :    name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,159 :    name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,161 :    name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,162 :    name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,164 :    name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,165 :    name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,166 :    name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,168 :    name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,169 :    name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,170 :    name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,172 :    name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,173 :    name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,175 :    name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,176 :    name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,177 :    name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,178 :    name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,179 :    name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,180 :    name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,182 :    name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,184 :    name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,185 :    name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,187 :    name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,188 :    name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,189 :    name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,191 :    name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,192 :    name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,194 :    name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,195 :    name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,197 :    name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,198 :    name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,200 :    name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,201 :    name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,202 :    name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,203 :    name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,205 :    name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,206 :    name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,207 :    name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,209 :    name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,210 :    name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,211 :    name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,213 :    name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,214 :    name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,215 :    name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,217 :    name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,218 :    name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,219 :    name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,221 :    name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,222 :    name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,223 :    name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,224 :    name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,225 :    name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,226 :    name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,227 :    name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,229 :    name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,231 :    name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,232 :    name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,233 :    name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,234 :    name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,236 :    name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,237 :    name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,239 :    name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,240 :    name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,242 :    name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,243 :    name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,244 :    name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,245 :    name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,247 :    name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,248 :    name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,249 :    name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,251 :    name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,252 :    name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,254 :    name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,255 :    name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,256 :    name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,257 :    name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,259 :    name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,260 :    name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,262 :    name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,263 :    name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,264 :    name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,265 :    name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,267 :    name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,268 :    name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,270 :    name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,271 :    name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,272 :    name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,273 :    name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,274 :    name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,276 :    name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,277 :    name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,278 :    name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,280 :    name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,282 :    name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,284 :    name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,285 :    name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,286 :    name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,287 :    name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,289 :    name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,290 :    name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,291 :    name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,293 :    name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,294 :    name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,295 :    name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,296 :    name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,297 :    name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,299 :    name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,300 :    name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,302 :    name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,303 :    name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,304 :    name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,305 :    name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,307 :    name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,308 :    name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,309 :    name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,310 :    name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,311 :    name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,322 :    name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,323 :    name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,323 :    name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,324 :    name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,326 :    name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,328 :    name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,329 :    name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,330 :    name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,331 :    name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,332 :    name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,334 :    name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,335 :    name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,337 :    name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,338 :    name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,339 :    name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,341 :    name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,342 :    name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,343 :    name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,344 :    name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,346 :    name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,346 :    name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,348 :    name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,349 :    name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,349 :    name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,350 :    name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,351 :    name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,353 :    name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,355 :    name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,356 :    name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,357 :    name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,358 :    name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:32,359 :    name = output_weights:0, shape = (2, 768)\n","2020-01-31 01:56:32,361 :    name = output_bias:0, shape = (2,)\n","2020-01-31 01:56:32,365 :  From /content/bert/run_classifier.py:686: The name tf.metrics.accuracy is deprecated. Please use tf.compat.v1.metrics.accuracy instead.\n","\n","2020-01-31 01:56:32,403 :  From /content/bert/run_classifier.py:689: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.\n","\n","2020-01-31 01:56:32,432 :  Done calling model_fn.\n","2020-01-31 01:56:32,472 :  Starting evaluation at 2020-01-31T01:56:32Z\n","2020-01-31 01:56:33,060 :  Graph was finalized.\n","2020-01-31 01:56:33,074 :  Restoring parameters from ./finetuned_model/model.ckpt-0\n","2020-01-31 01:56:50,593 :  Running local_init_op.\n","2020-01-31 01:56:50,658 :  Done running local_init_op.\n","2020-01-31 01:56:51,846 :  Evaluation [1/5]\n","2020-01-31 01:56:52,420 :  Evaluation [2/5]\n","2020-01-31 01:56:52,988 :  Evaluation [3/5]\n","2020-01-31 01:56:53,575 :  Evaluation [4/5]\n","2020-01-31 01:56:54,143 :  Evaluation [5/5]\n","2020-01-31 01:56:54,282 :  Finished evaluation at 2020-01-31-01:56:54\n","2020-01-31 01:56:54,283 :  Saving dict for global step 0: eval_accuracy = 0.528125, eval_loss = 0.6959344, global_step = 0, loss = 0.6959344\n","2020-01-31 01:56:55,165 :  Saving 'checkpoint_path' summary for global step 0: ./finetuned_model/model.ckpt-0\n","2020-01-31 01:56:55,170 :  evaluation_loop marked as finished\n","2020-01-31 01:56:55,171 :  ***** Eval results *****\n","2020-01-31 01:56:55,172 :    eval_accuracy = 0.528125\n","2020-01-31 01:56:55,174 :    eval_loss = 0.6959344\n","2020-01-31 01:56:55,175 :    global_step = 0\n","2020-01-31 01:56:55,176 :    loss = 0.6959344\n"," 14%|█▍        | 1/7 [00:25<02:31, 25.24s/it]2020-01-31 01:56:55,306 :  Calling model_fn.\n","2020-01-31 01:56:55,307 :  Running eval on CPU\n","2020-01-31 01:56:55,309 :  *** Features ***\n","2020-01-31 01:56:55,310 :    name = input_ids, shape = (64, 128)\n","2020-01-31 01:56:55,311 :    name = input_mask, shape = (64, 128)\n","2020-01-31 01:56:55,311 :    name = label_ids, shape = (64,)\n","2020-01-31 01:56:55,312 :    name = segment_ids, shape = (64, 128)\n","2020-01-31 01:56:57,233 :  **** Trainable Variables ****\n","2020-01-31 01:56:57,234 :    name = bert/embeddings/word_embeddings:0, shape = (64000, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,235 :    name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,236 :    name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,237 :    name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,238 :    name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,239 :    name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,240 :    name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,241 :    name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,242 :    name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,245 :    name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,247 :    name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,249 :    name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,251 :    name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,253 :    name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,255 :    name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,257 :    name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,258 :    name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,260 :    name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,262 :    name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,264 :    name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,265 :    name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,266 :    name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,270 :    name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,271 :    name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,272 :    name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,273 :    name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,275 :    name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,276 :    name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,280 :    name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,283 :    name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,286 :    name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,289 :    name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,291 :    name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,294 :    name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,296 :    name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,299 :    name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,301 :    name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,302 :    name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,303 :    name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,310 :    name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,315 :    name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,319 :    name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,322 :    name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,325 :    name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,328 :    name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,331 :    name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,332 :    name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,333 :    name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,335 :    name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,338 :    name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,339 :    name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,341 :    name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,342 :    name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,343 :    name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,344 :    name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,345 :    name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,346 :    name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,346 :    name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,347 :    name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,348 :    name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,349 :    name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,350 :    name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,351 :    name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,352 :    name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,353 :    name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,353 :    name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,354 :    name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,355 :    name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,356 :    name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,357 :    name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,358 :    name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,359 :    name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,359 :    name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,360 :    name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,361 :    name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,362 :    name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,363 :    name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,363 :    name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,364 :    name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,365 :    name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,366 :    name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,367 :    name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,368 :    name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,369 :    name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,369 :    name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,370 :    name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,371 :    name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,372 :    name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,373 :    name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,373 :    name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,374 :    name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,375 :    name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,376 :    name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,377 :    name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,378 :    name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,378 :    name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,379 :    name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,380 :    name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,381 :    name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,382 :    name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,383 :    name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,383 :    name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,384 :    name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,385 :    name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,386 :    name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,387 :    name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,387 :    name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,388 :    name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,389 :    name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,390 :    name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,391 :    name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,392 :    name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,393 :    name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,393 :    name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,394 :    name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,395 :    name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,396 :    name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,397 :    name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,398 :    name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,398 :    name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,399 :    name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,400 :    name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,402 :    name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,403 :    name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,404 :    name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,406 :    name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,410 :    name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,413 :    name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,416 :    name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,418 :    name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,422 :    name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,424 :    name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,426 :    name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,427 :    name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,433 :    name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,439 :    name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,444 :    name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,467 :    name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,469 :    name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,470 :    name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,471 :    name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,475 :    name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,480 :    name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,482 :    name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,484 :    name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,485 :    name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,487 :    name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,494 :    name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,497 :    name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,499 :    name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,504 :    name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,506 :    name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,507 :    name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,508 :    name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,509 :    name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,511 :    name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,512 :    name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,513 :    name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,514 :    name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,514 :    name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,516 :    name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,517 :    name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,518 :    name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,519 :    name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,520 :    name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,521 :    name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,522 :    name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,523 :    name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,525 :    name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,526 :    name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,527 :    name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,528 :    name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,529 :    name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,530 :    name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,531 :    name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,532 :    name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,533 :    name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,535 :    name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,536 :    name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,537 :    name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,538 :    name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,539 :    name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,540 :    name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,541 :    name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,543 :    name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,544 :    name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,545 :    name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,547 :    name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,547 :    name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,549 :    name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,550 :    name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,551 :    name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,552 :    name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,553 :    name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,554 :    name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,555 :    name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,556 :    name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,557 :    name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,558 :    name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:56:57,560 :    name = output_weights:0, shape = (2, 768)\n","2020-01-31 01:56:57,561 :    name = output_bias:0, shape = (2,)\n","2020-01-31 01:56:57,610 :  Done calling model_fn.\n","2020-01-31 01:56:57,639 :  Starting evaluation at 2020-01-31T01:56:57Z\n","2020-01-31 01:56:58,163 :  Graph was finalized.\n","2020-01-31 01:56:58,174 :  Restoring parameters from ./finetuned_model/model.ckpt-45\n","2020-01-31 01:57:15,640 :  Running local_init_op.\n","2020-01-31 01:57:15,716 :  Done running local_init_op.\n","2020-01-31 01:57:16,907 :  Evaluation [1/5]\n","2020-01-31 01:57:17,487 :  Evaluation [2/5]\n","2020-01-31 01:57:18,049 :  Evaluation [3/5]\n","2020-01-31 01:57:18,632 :  Evaluation [4/5]\n","2020-01-31 01:57:19,191 :  Evaluation [5/5]\n","2020-01-31 01:57:19,302 :  Finished evaluation at 2020-01-31-01:57:19\n","2020-01-31 01:57:19,303 :  Saving dict for global step 45: eval_accuracy = 0.89375, eval_loss = 0.27333134, global_step = 45, loss = 0.27333134\n","2020-01-31 01:57:19,305 :  Saving 'checkpoint_path' summary for global step 45: ./finetuned_model/model.ckpt-45\n","2020-01-31 01:57:19,306 :  evaluation_loop marked as finished\n","2020-01-31 01:57:19,308 :  ***** Eval results *****\n","2020-01-31 01:57:19,309 :    eval_accuracy = 0.89375\n","2020-01-31 01:57:19,310 :    eval_loss = 0.27333134\n","2020-01-31 01:57:19,311 :    global_step = 45\n","2020-01-31 01:57:19,312 :    loss = 0.27333134\n"," 29%|██▊       | 2/7 [00:49<02:04, 24.91s/it]2020-01-31 01:57:19,438 :  Calling model_fn.\n","2020-01-31 01:57:19,439 :  Running eval on CPU\n","2020-01-31 01:57:19,441 :  *** Features ***\n","2020-01-31 01:57:19,441 :    name = input_ids, shape = (64, 128)\n","2020-01-31 01:57:19,443 :    name = input_mask, shape = (64, 128)\n","2020-01-31 01:57:19,444 :    name = label_ids, shape = (64,)\n","2020-01-31 01:57:19,445 :    name = segment_ids, shape = (64, 128)\n","2020-01-31 01:57:21,439 :  **** Trainable Variables ****\n","2020-01-31 01:57:21,440 :    name = bert/embeddings/word_embeddings:0, shape = (64000, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,441 :    name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,441 :    name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,442 :    name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,443 :    name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,445 :    name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,446 :    name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,447 :    name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,448 :    name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,449 :    name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,451 :    name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,452 :    name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,453 :    name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,454 :    name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,455 :    name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,456 :    name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,457 :    name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,458 :    name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,460 :    name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,460 :    name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,462 :    name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,463 :    name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,464 :    name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,465 :    name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,466 :    name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,467 :    name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,469 :    name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,470 :    name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,471 :    name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,472 :    name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,473 :    name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,474 :    name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,475 :    name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,476 :    name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,477 :    name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,478 :    name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,479 :    name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,481 :    name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,482 :    name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,483 :    name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,484 :    name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,485 :    name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,486 :    name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,487 :    name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,488 :    name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,489 :    name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,490 :    name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,491 :    name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,493 :    name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,493 :    name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,495 :    name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,496 :    name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,497 :    name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,498 :    name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,499 :    name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,500 :    name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,501 :    name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,502 :    name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,503 :    name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,504 :    name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,505 :    name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,507 :    name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,508 :    name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,509 :    name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,510 :    name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,510 :    name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,512 :    name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,512 :    name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,514 :    name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,515 :    name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,516 :    name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,517 :    name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,518 :    name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,519 :    name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,520 :    name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,521 :    name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,523 :    name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,524 :    name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,525 :    name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,526 :    name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,527 :    name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,527 :    name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,528 :    name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,530 :    name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,531 :    name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,532 :    name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,533 :    name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,533 :    name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,534 :    name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,535 :    name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,536 :    name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,537 :    name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,538 :    name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,539 :    name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,540 :    name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,541 :    name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,542 :    name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,543 :    name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,544 :    name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,545 :    name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,546 :    name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,547 :    name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,548 :    name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,549 :    name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,550 :    name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,551 :    name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,552 :    name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,553 :    name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,555 :    name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,556 :    name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,557 :    name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,558 :    name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,559 :    name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,561 :    name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,562 :    name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,564 :    name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,565 :    name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,566 :    name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,567 :    name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,569 :    name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,570 :    name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,571 :    name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,572 :    name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,573 :    name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,573 :    name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,574 :    name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,575 :    name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,576 :    name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,576 :    name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,577 :    name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,578 :    name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,579 :    name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,580 :    name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,581 :    name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,582 :    name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,584 :    name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,585 :    name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,586 :    name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,587 :    name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,589 :    name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,590 :    name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,591 :    name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,592 :    name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,594 :    name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,595 :    name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,596 :    name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,598 :    name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,599 :    name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,600 :    name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,601 :    name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,603 :    name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,604 :    name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,605 :    name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,606 :    name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,607 :    name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,609 :    name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,610 :    name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,612 :    name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,613 :    name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,614 :    name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,615 :    name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,617 :    name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,617 :    name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,619 :    name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,620 :    name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,621 :    name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,622 :    name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,624 :    name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,625 :    name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,627 :    name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,628 :    name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,630 :    name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,631 :    name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,632 :    name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,633 :    name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,635 :    name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,636 :    name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,637 :    name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,638 :    name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,640 :    name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,641 :    name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,642 :    name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,644 :    name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,645 :    name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,646 :    name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,648 :    name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,650 :    name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,652 :    name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,654 :    name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,655 :    name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,656 :    name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,658 :    name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,659 :    name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,660 :    name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,661 :    name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,663 :    name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,665 :    name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,666 :    name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,667 :    name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:21,668 :    name = output_weights:0, shape = (2, 768)\n","2020-01-31 01:57:21,670 :    name = output_bias:0, shape = (2,)\n","2020-01-31 01:57:21,731 :  Done calling model_fn.\n","2020-01-31 01:57:21,770 :  Starting evaluation at 2020-01-31T01:57:21Z\n","2020-01-31 01:57:22,351 :  Graph was finalized.\n","2020-01-31 01:57:22,360 :  Restoring parameters from ./finetuned_model/model.ckpt-90\n","2020-01-31 01:57:39,853 :  Running local_init_op.\n","2020-01-31 01:57:39,924 :  Done running local_init_op.\n","2020-01-31 01:57:41,146 :  Evaluation [1/5]\n","2020-01-31 01:57:41,714 :  Evaluation [2/5]\n","2020-01-31 01:57:42,281 :  Evaluation [3/5]\n","2020-01-31 01:57:42,860 :  Evaluation [4/5]\n","2020-01-31 01:57:43,427 :  Evaluation [5/5]\n","2020-01-31 01:57:43,546 :  Finished evaluation at 2020-01-31-01:57:43\n","2020-01-31 01:57:43,547 :  Saving dict for global step 90: eval_accuracy = 0.9375, eval_loss = 0.2181972, global_step = 90, loss = 0.2181972\n","2020-01-31 01:57:43,548 :  Saving 'checkpoint_path' summary for global step 90: ./finetuned_model/model.ckpt-90\n","2020-01-31 01:57:43,550 :  evaluation_loop marked as finished\n","2020-01-31 01:57:43,551 :  ***** Eval results *****\n","2020-01-31 01:57:43,552 :    eval_accuracy = 0.9375\n","2020-01-31 01:57:43,553 :    eval_loss = 0.2181972\n","2020-01-31 01:57:43,554 :    global_step = 90\n","2020-01-31 01:57:43,555 :    loss = 0.2181972\n"," 43%|████▎     | 3/7 [01:13<01:38, 24.71s/it]2020-01-31 01:57:43,681 :  Calling model_fn.\n","2020-01-31 01:57:43,682 :  Running eval on CPU\n","2020-01-31 01:57:43,683 :  *** Features ***\n","2020-01-31 01:57:43,684 :    name = input_ids, shape = (64, 128)\n","2020-01-31 01:57:43,685 :    name = input_mask, shape = (64, 128)\n","2020-01-31 01:57:43,686 :    name = label_ids, shape = (64,)\n","2020-01-31 01:57:43,687 :    name = segment_ids, shape = (64, 128)\n","2020-01-31 01:57:46,011 :  **** Trainable Variables ****\n","2020-01-31 01:57:46,012 :    name = bert/embeddings/word_embeddings:0, shape = (64000, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,013 :    name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,014 :    name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,015 :    name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,016 :    name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,017 :    name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,018 :    name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,019 :    name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,020 :    name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,021 :    name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,022 :    name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,023 :    name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,024 :    name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,025 :    name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,026 :    name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,027 :    name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,028 :    name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,029 :    name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,030 :    name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,031 :    name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,031 :    name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,032 :    name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,033 :    name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,034 :    name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,035 :    name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,036 :    name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,037 :    name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,038 :    name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,038 :    name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,039 :    name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,040 :    name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,041 :    name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,042 :    name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,043 :    name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,044 :    name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,045 :    name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,046 :    name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,047 :    name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,048 :    name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,049 :    name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,050 :    name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,051 :    name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,052 :    name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,052 :    name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,053 :    name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,054 :    name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,055 :    name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,056 :    name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,057 :    name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,058 :    name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,059 :    name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,060 :    name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,061 :    name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,062 :    name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,063 :    name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,064 :    name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,065 :    name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,066 :    name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,067 :    name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,068 :    name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,068 :    name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,069 :    name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,070 :    name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,071 :    name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,072 :    name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,073 :    name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,074 :    name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,075 :    name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,076 :    name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,077 :    name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,078 :    name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,079 :    name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,080 :    name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,081 :    name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,081 :    name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,082 :    name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,083 :    name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,084 :    name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,085 :    name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,086 :    name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,087 :    name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,088 :    name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,089 :    name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,090 :    name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,091 :    name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,092 :    name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,093 :    name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,094 :    name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,094 :    name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,095 :    name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,096 :    name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,097 :    name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,098 :    name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,099 :    name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,100 :    name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,101 :    name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,102 :    name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,103 :    name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,104 :    name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,105 :    name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,106 :    name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,106 :    name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,107 :    name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,108 :    name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,109 :    name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,110 :    name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,111 :    name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,112 :    name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,113 :    name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,114 :    name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,115 :    name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,116 :    name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,117 :    name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,118 :    name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,119 :    name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,119 :    name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,120 :    name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,121 :    name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,122 :    name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,123 :    name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,124 :    name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,125 :    name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,126 :    name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,127 :    name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,128 :    name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,128 :    name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,129 :    name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,130 :    name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,131 :    name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,132 :    name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,133 :    name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,134 :    name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,135 :    name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,136 :    name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,137 :    name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,138 :    name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,139 :    name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,140 :    name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,142 :    name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,143 :    name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,144 :    name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,145 :    name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,145 :    name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,146 :    name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,147 :    name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,148 :    name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,149 :    name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,150 :    name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,151 :    name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,152 :    name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,153 :    name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,154 :    name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,155 :    name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,156 :    name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,157 :    name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,158 :    name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,158 :    name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,159 :    name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,160 :    name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,161 :    name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,162 :    name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,163 :    name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,164 :    name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,165 :    name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,166 :    name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,167 :    name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,168 :    name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,169 :    name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,170 :    name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,171 :    name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,172 :    name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,173 :    name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,174 :    name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,175 :    name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,176 :    name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,177 :    name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,178 :    name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,179 :    name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,180 :    name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,181 :    name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,182 :    name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,183 :    name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,184 :    name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,185 :    name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,186 :    name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,187 :    name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,188 :    name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,189 :    name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,190 :    name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,191 :    name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,192 :    name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,193 :    name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,194 :    name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,195 :    name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,195 :    name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,196 :    name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,197 :    name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,198 :    name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,199 :    name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:57:46,200 :    name = output_weights:0, shape = (2, 768)\n","2020-01-31 01:57:46,201 :    name = output_bias:0, shape = (2,)\n","2020-01-31 01:57:46,248 :  Done calling model_fn.\n","2020-01-31 01:57:46,278 :  Starting evaluation at 2020-01-31T01:57:46Z\n","2020-01-31 01:57:46,869 :  Graph was finalized.\n","2020-01-31 01:57:46,879 :  Restoring parameters from ./finetuned_model/model.ckpt-135\n","2020-01-31 01:58:04,376 :  Running local_init_op.\n","2020-01-31 01:58:04,449 :  Done running local_init_op.\n","2020-01-31 01:58:05,643 :  Evaluation [1/5]\n","2020-01-31 01:58:06,214 :  Evaluation [2/5]\n","2020-01-31 01:58:06,781 :  Evaluation [3/5]\n","2020-01-31 01:58:07,364 :  Evaluation [4/5]\n","2020-01-31 01:58:07,928 :  Evaluation [5/5]\n","2020-01-31 01:58:08,041 :  Finished evaluation at 2020-01-31-01:58:08\n","2020-01-31 01:58:08,042 :  Saving dict for global step 135: eval_accuracy = 0.9125, eval_loss = 0.44617414, global_step = 135, loss = 0.44617414\n","2020-01-31 01:58:08,043 :  Saving 'checkpoint_path' summary for global step 135: ./finetuned_model/model.ckpt-135\n","2020-01-31 01:58:08,045 :  evaluation_loop marked as finished\n","2020-01-31 01:58:08,046 :  ***** Eval results *****\n","2020-01-31 01:58:08,047 :    eval_accuracy = 0.9125\n","2020-01-31 01:58:08,048 :    eval_loss = 0.44617414\n","2020-01-31 01:58:08,050 :    global_step = 135\n","2020-01-31 01:58:08,050 :    loss = 0.44617414\n"," 57%|█████▋    | 4/7 [01:38<01:13, 24.64s/it]2020-01-31 01:58:08,176 :  Calling model_fn.\n","2020-01-31 01:58:08,177 :  Running eval on CPU\n","2020-01-31 01:58:08,178 :  *** Features ***\n","2020-01-31 01:58:08,180 :    name = input_ids, shape = (64, 128)\n","2020-01-31 01:58:08,181 :    name = input_mask, shape = (64, 128)\n","2020-01-31 01:58:08,182 :    name = label_ids, shape = (64,)\n","2020-01-31 01:58:08,183 :    name = segment_ids, shape = (64, 128)\n","2020-01-31 01:58:10,233 :  **** Trainable Variables ****\n","2020-01-31 01:58:10,234 :    name = bert/embeddings/word_embeddings:0, shape = (64000, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,235 :    name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,237 :    name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,238 :    name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,240 :    name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,241 :    name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,243 :    name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,244 :    name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,245 :    name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,246 :    name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,247 :    name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,247 :    name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,249 :    name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,250 :    name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,251 :    name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,253 :    name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,254 :    name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,255 :    name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,256 :    name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,258 :    name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,259 :    name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,260 :    name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,261 :    name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,262 :    name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,264 :    name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,265 :    name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,266 :    name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,267 :    name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,269 :    name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,270 :    name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,271 :    name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,273 :    name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,274 :    name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,277 :    name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,278 :    name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,279 :    name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,281 :    name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,282 :    name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,282 :    name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,283 :    name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,284 :    name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,285 :    name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,286 :    name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,287 :    name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,289 :    name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,290 :    name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,291 :    name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,292 :    name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,294 :    name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,295 :    name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,298 :    name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,300 :    name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,301 :    name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,302 :    name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,304 :    name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,306 :    name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,307 :    name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,308 :    name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,309 :    name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,310 :    name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,312 :    name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,313 :    name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,314 :    name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,315 :    name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,317 :    name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,318 :    name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,319 :    name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,320 :    name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,321 :    name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,323 :    name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,324 :    name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,325 :    name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,326 :    name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,328 :    name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,329 :    name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,330 :    name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,331 :    name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,333 :    name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,334 :    name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,335 :    name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,337 :    name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,338 :    name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,339 :    name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,340 :    name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,341 :    name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,342 :    name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,345 :    name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,346 :    name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,347 :    name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,348 :    name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,349 :    name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,350 :    name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,352 :    name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,353 :    name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,354 :    name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,356 :    name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,357 :    name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,358 :    name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,359 :    name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,360 :    name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,362 :    name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,363 :    name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,364 :    name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,365 :    name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,366 :    name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,368 :    name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,369 :    name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,370 :    name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,373 :    name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,374 :    name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,376 :    name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,377 :    name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,379 :    name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,380 :    name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,381 :    name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,383 :    name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,384 :    name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,385 :    name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,387 :    name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,388 :    name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,389 :    name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,390 :    name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,392 :    name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,393 :    name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,394 :    name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,395 :    name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,396 :    name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,398 :    name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,399 :    name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,400 :    name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,401 :    name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,403 :    name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,404 :    name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,405 :    name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,407 :    name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,408 :    name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,409 :    name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,410 :    name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,412 :    name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,413 :    name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,414 :    name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,415 :    name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,416 :    name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,417 :    name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,418 :    name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,420 :    name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,422 :    name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,423 :    name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,424 :    name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,425 :    name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,426 :    name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,427 :    name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,429 :    name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,430 :    name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,431 :    name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,433 :    name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,435 :    name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,436 :    name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,437 :    name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,439 :    name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,440 :    name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,441 :    name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,443 :    name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,445 :    name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,447 :    name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,448 :    name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,449 :    name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,451 :    name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,451 :    name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,453 :    name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,453 :    name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,455 :    name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,457 :    name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,459 :    name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,460 :    name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,461 :    name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,462 :    name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,464 :    name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,465 :    name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,466 :    name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,468 :    name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,469 :    name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,470 :    name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,472 :    name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,473 :    name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,474 :    name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,476 :    name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,477 :    name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,478 :    name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,481 :    name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,482 :    name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,484 :    name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,485 :    name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,486 :    name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,488 :    name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,490 :    name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,491 :    name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,492 :    name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,494 :    name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:10,495 :    name = output_weights:0, shape = (2, 768)\n","2020-01-31 01:58:10,497 :    name = output_bias:0, shape = (2,)\n","2020-01-31 01:58:10,555 :  Done calling model_fn.\n","2020-01-31 01:58:10,588 :  Starting evaluation at 2020-01-31T01:58:10Z\n","2020-01-31 01:58:11,120 :  Graph was finalized.\n","2020-01-31 01:58:11,131 :  Restoring parameters from ./finetuned_model/model.ckpt-180\n","2020-01-31 01:58:28,626 :  Running local_init_op.\n","2020-01-31 01:58:28,708 :  Done running local_init_op.\n","2020-01-31 01:58:29,925 :  Evaluation [1/5]\n","2020-01-31 01:58:30,495 :  Evaluation [2/5]\n","2020-01-31 01:58:31,055 :  Evaluation [3/5]\n","2020-01-31 01:58:31,637 :  Evaluation [4/5]\n","2020-01-31 01:58:32,200 :  Evaluation [5/5]\n","2020-01-31 01:58:32,333 :  Finished evaluation at 2020-01-31-01:58:32\n","2020-01-31 01:58:32,334 :  Saving dict for global step 180: eval_accuracy = 0.928125, eval_loss = 0.40347257, global_step = 180, loss = 0.40347257\n","2020-01-31 01:58:32,335 :  Saving 'checkpoint_path' summary for global step 180: ./finetuned_model/model.ckpt-180\n","2020-01-31 01:58:32,338 :  evaluation_loop marked as finished\n","2020-01-31 01:58:32,339 :  ***** Eval results *****\n","2020-01-31 01:58:32,340 :    eval_accuracy = 0.928125\n","2020-01-31 01:58:32,342 :    eval_loss = 0.40347257\n","2020-01-31 01:58:32,343 :    global_step = 180\n","2020-01-31 01:58:32,344 :    loss = 0.40347257\n"," 71%|███████▏  | 5/7 [02:02<00:49, 24.54s/it]2020-01-31 01:58:32,465 :  Calling model_fn.\n","2020-01-31 01:58:32,466 :  Running eval on CPU\n","2020-01-31 01:58:32,467 :  *** Features ***\n","2020-01-31 01:58:32,468 :    name = input_ids, shape = (64, 128)\n","2020-01-31 01:58:32,469 :    name = input_mask, shape = (64, 128)\n","2020-01-31 01:58:32,470 :    name = label_ids, shape = (64,)\n","2020-01-31 01:58:32,471 :    name = segment_ids, shape = (64, 128)\n","2020-01-31 01:58:34,773 :  **** Trainable Variables ****\n","2020-01-31 01:58:34,774 :    name = bert/embeddings/word_embeddings:0, shape = (64000, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,778 :    name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,780 :    name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,781 :    name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,782 :    name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,787 :    name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,788 :    name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,789 :    name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,790 :    name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,791 :    name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,792 :    name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,793 :    name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,794 :    name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,795 :    name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,796 :    name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,797 :    name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,798 :    name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,799 :    name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,801 :    name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,802 :    name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,803 :    name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,804 :    name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,805 :    name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,806 :    name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,807 :    name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,809 :    name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,810 :    name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,810 :    name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,812 :    name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,812 :    name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,814 :    name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,817 :    name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,818 :    name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,819 :    name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,819 :    name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,820 :    name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,821 :    name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,821 :    name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,822 :    name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,825 :    name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,826 :    name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,827 :    name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,828 :    name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,829 :    name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,831 :    name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,832 :    name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,833 :    name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,834 :    name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,836 :    name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,837 :    name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,838 :    name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,840 :    name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,841 :    name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,842 :    name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,842 :    name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,844 :    name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,845 :    name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,846 :    name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,847 :    name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,848 :    name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,849 :    name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,850 :    name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,851 :    name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,852 :    name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,853 :    name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,854 :    name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,855 :    name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,857 :    name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,857 :    name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,858 :    name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,860 :    name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,861 :    name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,861 :    name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,862 :    name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,863 :    name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,865 :    name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,866 :    name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,866 :    name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,867 :    name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,868 :    name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,870 :    name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,871 :    name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,871 :    name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,873 :    name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,873 :    name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,874 :    name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,875 :    name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,877 :    name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,878 :    name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,879 :    name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,880 :    name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,880 :    name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,882 :    name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,882 :    name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,883 :    name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,885 :    name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,886 :    name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,887 :    name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,888 :    name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,889 :    name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,890 :    name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,892 :    name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,893 :    name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,893 :    name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,895 :    name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,895 :    name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,896 :    name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,898 :    name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,899 :    name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,900 :    name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,901 :    name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,902 :    name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,903 :    name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,904 :    name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,905 :    name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,906 :    name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,907 :    name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,908 :    name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,910 :    name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,910 :    name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,911 :    name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,913 :    name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,913 :    name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,914 :    name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,915 :    name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,917 :    name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,918 :    name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,919 :    name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,920 :    name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,921 :    name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,922 :    name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,924 :    name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,925 :    name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,926 :    name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,927 :    name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,928 :    name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,928 :    name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,930 :    name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,930 :    name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,932 :    name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,933 :    name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,934 :    name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,935 :    name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,936 :    name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,937 :    name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,938 :    name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,940 :    name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,941 :    name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,942 :    name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,943 :    name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,943 :    name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,945 :    name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,946 :    name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,947 :    name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,948 :    name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,949 :    name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,950 :    name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,951 :    name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,952 :    name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,953 :    name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,954 :    name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,955 :    name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,956 :    name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,957 :    name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,958 :    name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,959 :    name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,960 :    name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,961 :    name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,962 :    name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,963 :    name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,965 :    name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,966 :    name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,966 :    name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,968 :    name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,968 :    name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,969 :    name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,970 :    name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,972 :    name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,973 :    name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,974 :    name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,975 :    name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,976 :    name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,977 :    name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,978 :    name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,979 :    name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,979 :    name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,986 :    name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,987 :    name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,988 :    name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,989 :    name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,990 :    name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,991 :    name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,992 :    name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,993 :    name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,995 :    name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,995 :    name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,997 :    name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,997 :    name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:34,999 :    name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:35,001 :    name = output_weights:0, shape = (2, 768)\n","2020-01-31 01:58:35,001 :    name = output_bias:0, shape = (2,)\n","2020-01-31 01:58:35,064 :  Done calling model_fn.\n","2020-01-31 01:58:35,113 :  Starting evaluation at 2020-01-31T01:58:35Z\n","2020-01-31 01:58:35,636 :  Graph was finalized.\n","2020-01-31 01:58:35,648 :  Restoring parameters from ./finetuned_model/model.ckpt-225\n","2020-01-31 01:58:53,159 :  Running local_init_op.\n","2020-01-31 01:58:53,231 :  Done running local_init_op.\n","2020-01-31 01:58:54,447 :  Evaluation [1/5]\n","2020-01-31 01:58:55,027 :  Evaluation [2/5]\n","2020-01-31 01:58:55,578 :  Evaluation [3/5]\n","2020-01-31 01:58:56,158 :  Evaluation [4/5]\n","2020-01-31 01:58:56,715 :  Evaluation [5/5]\n","2020-01-31 01:58:56,829 :  Finished evaluation at 2020-01-31-01:58:56\n","2020-01-31 01:58:56,830 :  Saving dict for global step 225: eval_accuracy = 0.90625, eval_loss = 0.43799916, global_step = 225, loss = 0.43799916\n","2020-01-31 01:58:56,832 :  Saving 'checkpoint_path' summary for global step 225: ./finetuned_model/model.ckpt-225\n","2020-01-31 01:58:56,834 :  evaluation_loop marked as finished\n","2020-01-31 01:58:56,835 :  ***** Eval results *****\n","2020-01-31 01:58:56,836 :    eval_accuracy = 0.90625\n","2020-01-31 01:58:56,837 :    eval_loss = 0.43799916\n","2020-01-31 01:58:56,839 :    global_step = 225\n","2020-01-31 01:58:56,840 :    loss = 0.43799916\n"," 86%|████████▌ | 6/7 [02:26<00:24, 24.53s/it]2020-01-31 01:58:56,965 :  Calling model_fn.\n","2020-01-31 01:58:56,966 :  Running eval on CPU\n","2020-01-31 01:58:56,967 :  *** Features ***\n","2020-01-31 01:58:56,968 :    name = input_ids, shape = (64, 128)\n","2020-01-31 01:58:56,969 :    name = input_mask, shape = (64, 128)\n","2020-01-31 01:58:56,971 :    name = label_ids, shape = (64,)\n","2020-01-31 01:58:56,972 :    name = segment_ids, shape = (64, 128)\n","2020-01-31 01:58:58,902 :  **** Trainable Variables ****\n","2020-01-31 01:58:58,903 :    name = bert/embeddings/word_embeddings:0, shape = (64000, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,904 :    name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,905 :    name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,906 :    name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,907 :    name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,908 :    name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,909 :    name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,910 :    name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,911 :    name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,913 :    name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,914 :    name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,915 :    name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,916 :    name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,917 :    name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,918 :    name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,919 :    name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,920 :    name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,921 :    name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,922 :    name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,923 :    name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,924 :    name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,926 :    name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,926 :    name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,927 :    name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,929 :    name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,930 :    name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,931 :    name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,932 :    name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,932 :    name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,933 :    name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,935 :    name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,936 :    name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,937 :    name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,938 :    name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,939 :    name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,940 :    name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,941 :    name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,942 :    name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,943 :    name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,944 :    name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,945 :    name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,946 :    name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,947 :    name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,948 :    name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,949 :    name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,951 :    name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,951 :    name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,952 :    name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,953 :    name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,953 :    name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,954 :    name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,955 :    name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,955 :    name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,956 :    name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,956 :    name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,957 :    name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,958 :    name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,958 :    name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,960 :    name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,961 :    name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,962 :    name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,963 :    name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,964 :    name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,965 :    name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,967 :    name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,967 :    name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,969 :    name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,969 :    name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,970 :    name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,971 :    name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,973 :    name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,974 :    name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,975 :    name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,976 :    name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,977 :    name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,978 :    name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,979 :    name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,980 :    name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,981 :    name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,982 :    name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,983 :    name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,984 :    name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,985 :    name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,986 :    name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,987 :    name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,988 :    name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,989 :    name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,990 :    name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,991 :    name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,992 :    name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,994 :    name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,995 :    name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,995 :    name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,996 :    name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,998 :    name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:58,999 :    name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,000 :    name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,001 :    name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,002 :    name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,003 :    name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,004 :    name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,005 :    name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,006 :    name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,007 :    name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,008 :    name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,009 :    name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,010 :    name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,011 :    name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,012 :    name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,013 :    name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,014 :    name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,015 :    name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,017 :    name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,018 :    name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,019 :    name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,020 :    name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,021 :    name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,022 :    name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,023 :    name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,024 :    name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,025 :    name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,027 :    name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,027 :    name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,029 :    name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,030 :    name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,031 :    name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,032 :    name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,033 :    name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,034 :    name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,034 :    name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,035 :    name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,036 :    name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,038 :    name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,039 :    name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,040 :    name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,041 :    name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,042 :    name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,043 :    name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,044 :    name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,045 :    name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,047 :    name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,048 :    name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,049 :    name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,051 :    name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,052 :    name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,053 :    name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,054 :    name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,055 :    name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,056 :    name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,057 :    name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,059 :    name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,060 :    name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,061 :    name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,062 :    name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,063 :    name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,065 :    name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,066 :    name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,067 :    name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,068 :    name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,069 :    name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,070 :    name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,071 :    name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,072 :    name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,073 :    name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,074 :    name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,075 :    name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,076 :    name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,077 :    name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,078 :    name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,079 :    name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,080 :    name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,081 :    name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,082 :    name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,084 :    name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,085 :    name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,085 :    name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,086 :    name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,088 :    name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,088 :    name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,089 :    name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,090 :    name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,092 :    name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,093 :    name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,093 :    name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,095 :    name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,096 :    name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,096 :    name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,098 :    name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,098 :    name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,100 :    name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,100 :    name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,102 :    name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,103 :    name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,104 :    name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,106 :    name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,107 :    name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,108 :    name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,109 :    name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,110 :    name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","2020-01-31 01:58:59,112 :    name = output_weights:0, shape = (2, 768)\n","2020-01-31 01:58:59,113 :    name = output_bias:0, shape = (2,)\n","2020-01-31 01:58:59,177 :  Done calling model_fn.\n","2020-01-31 01:58:59,216 :  Starting evaluation at 2020-01-31T01:58:59Z\n","2020-01-31 01:58:59,768 :  Graph was finalized.\n","2020-01-31 01:58:59,778 :  Restoring parameters from ./finetuned_model/model.ckpt-270\n","2020-01-31 01:59:17,276 :  Running local_init_op.\n","2020-01-31 01:59:17,357 :  Done running local_init_op.\n","2020-01-31 01:59:18,570 :  Evaluation [1/5]\n","2020-01-31 01:59:19,137 :  Evaluation [2/5]\n","2020-01-31 01:59:19,695 :  Evaluation [3/5]\n","2020-01-31 01:59:20,274 :  Evaluation [4/5]\n","2020-01-31 01:59:20,831 :  Evaluation [5/5]\n","2020-01-31 01:59:20,957 :  Finished evaluation at 2020-01-31-01:59:20\n","2020-01-31 01:59:20,959 :  Saving dict for global step 270: eval_accuracy = 0.9125, eval_loss = 0.43692517, global_step = 270, loss = 0.43692517\n","2020-01-31 01:59:20,963 :  Saving 'checkpoint_path' summary for global step 270: ./finetuned_model/model.ckpt-270\n","2020-01-31 01:59:20,965 :  evaluation_loop marked as finished\n","2020-01-31 01:59:20,967 :  ***** Eval results *****\n","2020-01-31 01:59:20,969 :    eval_accuracy = 0.9125\n","2020-01-31 01:59:20,971 :    eval_loss = 0.43692517\n","2020-01-31 01:59:20,973 :    global_step = 270\n","2020-01-31 01:59:20,975 :    loss = 0.43692517\n","100%|██████████| 7/7 [02:51<00:00, 24.41s/it]\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"2rGGQj6BUfal"},"source":["##Results\n","\n","araBERT achieved >93 acc on AJGT compared to 84 for mBERT (Tested prev, you can also try it using tf_hub scripts)\n","\n","we think that araBERT can get better score with more data cleaning and preprocessing.\n","\n","It also shows shows that it can adapt well for dialectal data (which is the most comon)"]},{"cell_type":"code","metadata":{"id":"kCmIvrMRUe5k"},"source":[""],"execution_count":null,"outputs":[]}]}